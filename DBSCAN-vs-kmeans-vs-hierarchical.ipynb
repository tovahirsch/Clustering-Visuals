{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Comparing Clustering Algorithm Effectiveness\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, you'll test three of the clustering algorithms we've covered on seven data sets that are specifically designed to evaluate clustering algorithm effectiveness.\n",
    "\n",
    "This lab is exploratory and heavy on data visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, k_means\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import hdbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1) Load the data sets.\n",
    "\n",
    "Each of the seven data sets have three columns:\n",
    "\n",
    "    x\n",
    "    y\n",
    "    label\n",
    "    \n",
    "Because they each only have two variables, they're easy to examine visually. You’ll compare the “true” labels for the data to the clusters the algorithms find.\n",
    "\n",
    "> Remember that in unsupervised learning methods like clustering, you will generally _not_ have \"true labels.\"  They are provided here simply as a convenience to give you some behind-the-scenes insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flame = pd.read_csv('./datasets/flame.csv')\n",
    "agg = pd.read_csv('./datasets/aggregation.csv')\n",
    "comp = pd.read_csv('./datasets/compound.csv')\n",
    "jain = pd.read_csv('./datasets/jain.csv')\n",
    "path = pd.read_csv('./datasets/pathbased.csv')\n",
    "r15 = pd.read_csv('./datasets/r15.csv')\n",
    "spiral = pd.read_csv('./datasets/spiral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flame.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jain.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r15.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spiral.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Plot each of the data sets with colored true labels.\n",
    "\n",
    "The data sets have different numbers of unique labels, so you'll need to figure out how many there are for each and color the clusters accordingly (for example, `r15` has 15 different clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting function.\n",
    "def plot_clusters(df, title):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(df.label.unique())))\n",
    "    \n",
    "    for label, color in zip(df.label.unique(), colors):\n",
    "        X = df[df.label == label]\n",
    "        ax.scatter(X.iloc[:,0], X.iloc[:,1], s=70, \n",
    "                   color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot each data set with the true cluster labels.\n",
    "plot_clusters(flame,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(agg,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(comp,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(jain,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(path,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(r15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(spiral,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Write a plotting function (or functions) to compare the performance of the three clustering algorithms.\n",
    "\n",
    "Load in the three clustering algorithms we covered earlier in the class.\n",
    "\n",
    "    K-means: k-means clustering.\n",
    "    Agglomerative clustering: hierarchical clustering (bottom up).\n",
    "    DBSCAN: density-based clustering.\n",
    "    \n",
    "Your function(s) should allow you to visually examine the effects of changing different parameters in the clustering algorithms. The parameters you should explore, at minimum, are:\n",
    "\n",
    "    K-means:\n",
    "        n_clusters\n",
    "    Agglomerative clustering:\n",
    "        n_clusters\n",
    "    DBSCAN\n",
    "        eps\n",
    "        min_samples\n",
    "        \n",
    "Feel free to explore other parameters for these models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    colors = plt.cm.Spectral(np.linspace(0, 1, len(df.label.unique())))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def plotting (df, model, n_clusters=0, eps=0, min_samples=0, dist=0):\n",
    "    \n",
    "     fig, axarr = plt.subplots(1,4, figsize=(24,7))\n",
    "    \n",
    "    # True:\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(df.label.unique())))\n",
    "    \n",
    "    for label, color in zip(df.label.unique(), colors):\n",
    "        X_ = df[df.label == label]\n",
    "        axarr[0].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "                         color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    axarr[0].set_title(title+' '+'true', fontsize=20)\n",
    "    axarr[0].legend(loc='lower right')\n",
    "    \n",
    "    \n",
    "    if model.lower() == 'kmeans':\n",
    "        model = KMeans(n_clusters=n_clusters)\n",
    "        model.fit(df)\n",
    "        predicted = model.labels_\n",
    "        centroids = model.cluster_centers_\n",
    "        print(centroids)\n",
    "        \n",
    "        colors = plt.cm.Spectral(np.linspace(0, 1, len(predicted.unique())))\n",
    "            axarr[0].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "            color=color, predicted=label, alpha=0.9)\n",
    "            axarr[1].set_title(title+' '+'kmeans', fontsize=20)\n",
    "            axarr[1].legend(loc='lower right')\n",
    "             \n",
    "   \n",
    "#     elif model == 'clustering':\n",
    "#         clustering = (df, n_clusters=3, dist=10, eps=1, min_samples=1):\n",
    "#     elif model.lower() == 'dbscan';\n",
    "#         dbscn = DBSCAN(eps = eps,\n",
    "#               min_samples = min_samples) \n",
    "#         dbscn.fit(df)\n",
    "#         core_samples = dbscn.core_sample_indices_\n",
    "#     else:\n",
    "#         print('give a valid model')\n",
    "\n",
    "\n",
    "#     plt.figure(figsize=(10,10))\n",
    "\n",
    "#     df.plot(x=\"x\", y=\"y\", kind=\"scatter\", c=df['predicted'], colormap='gist_rainbow', alpha=.7)\n",
    "#     plt.scatter(centroids[:,:1], centroids[:,1:], marker='x', s=150, alpha=.7, c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotting(df, title, n_clusters_kmeans=3, n_clusters_agg=3,\n",
    "                         dbscan_eps=3, dbscan_min_samples=5):\n",
    "    \n",
    "    fig, axarr = plt.subplots(1,4, figsize=(24,7))\n",
    "    \n",
    "    # True:\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(df.label.unique())))\n",
    "    \n",
    "    for label, color in zip(df.label.unique(), colors):\n",
    "        X_ = df[df.label == label]\n",
    "        axarr[0].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "                         color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    axarr[0].set_title(title+' '+'true', fontsize=20)\n",
    "    axarr[0].legend(loc='lower right')\n",
    "    \n",
    "    # Set up x.\n",
    "    X = df.iloc[:, 0:2]\n",
    "    \n",
    "    # K-means:\n",
    "    kmeans = KMeans(n_clusters=n_clusters_kmeans)\n",
    "    kmeans.fit(X.iloc[:, 0:2])\n",
    "    \n",
    "    X['kmeans_label'] = kmeans.labels_\n",
    "    \n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(X.kmeans_label.unique())))\n",
    "    \n",
    "    for label, color in zip(X.kmeans_label.unique(), colors):\n",
    "        X_ = X[X.kmeans_label == label]\n",
    "        axarr[1].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "                         color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    axarr[1].set_title(title+' '+'kmeans', fontsize=20)\n",
    "    axarr[1].legend(loc='lower right')\n",
    "    \n",
    "    \n",
    "    # Hierarchical/agglomerative:\n",
    "    aggclust = AgglomerativeClustering(n_clusters=n_clusters_agg)\n",
    "    aggclust.fit(X.iloc[:, 0:2])\n",
    "    \n",
    "    X['aggclust_label'] = aggclust.labels_\n",
    "    \n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(X.aggclust_label.unique())))\n",
    "    \n",
    "    for label, color in zip(X.aggclust_label.unique(), colors):\n",
    "        X_ = X[X.aggclust_label == label]\n",
    "        axarr[2].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "                         color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    axarr[2].set_title(title+' '+'agglomerative', fontsize=20)\n",
    "    axarr[2].legend(loc='lower right')\n",
    "    \n",
    "    \n",
    "    # DBSCAN:\n",
    "    dbscan = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples)\n",
    "    dbscan.fit(X.iloc[:, 0:2])\n",
    "    \n",
    "    X['dbscan_label'] = dbscan.labels_\n",
    "    \n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(X.dbscan_label.unique())))\n",
    "    \n",
    "    for label, color in zip(X.dbscan_label.unique(), colors):\n",
    "        X_ = X[X.dbscan_label == label]\n",
    "        axarr[3].scatter(X_.iloc[:,0], X_.iloc[:,1], s=70, \n",
    "                         color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    axarr[3].set_title(title+' '+'DBSCAN', fontsize=20)\n",
    "    axarr[3].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " model == 'clustering':\n",
    "        clustering = (flame, n_clusters=3, dist=10, eps=1, min_samples=1):\n",
    "              plt.figure(figsize=(10,10))\n",
    "\n",
    "fig, ax =  plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.scatter(flame['x'], flame['y'], c=colors_2)\n",
    "plt.title('Heirarchical Clustering with '+str(dist) + ' Dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbscn = DBSCAN(eps = .4,\n",
    "              min_samples = 3) \n",
    "dbscn.fit(flame)\n",
    "core_samples = dbscn.core_sample_indices_\n",
    "\n",
    "fig, ax =  plt.subplots(figsize=(5,5))\n",
    "ax.scatter(flame['x'], flame['y'])\n",
    "plt.title('DBSCN Clustering with '+str(eps) + ' Eps, and ' + str(min_samples) + ' Min. samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(flame)\n",
    "\n",
    "predicted = model.labels_\n",
    "flame['predicted'] = predicted\n",
    "centroids = model.cluster_centers_\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "flame.plot(x=\"x\", y=\"y\", kind=\"scatter\", c=flame['predicted'], colormap='gist_rainbow', alpha=.7)\n",
    "plt.scatter(centroids[:,:1], centroids[:,-1:], marker='x', s=150, alpha=.7, c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroids[:,:1].shape, centroids[:,-1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that will plot the results of the three\n",
    "# clustering algorithms for comparison.\n",
    "# Plotting function.\n",
    "#kmeans= KMeans(n_clusters=k)\n",
    "def plot_kmeans(df, kmeans):\n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(n_clusters())))\n",
    "    \n",
    "    for n_clusters, color in zip(kmeans, colors):\n",
    "        X = kmeans\n",
    "        ax.scatter(X.iloc[:,0], X.iloc[:,1], s=70, \n",
    "                   color=color, label=label, alpha=0.9)\n",
    "        \n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = range(1,10)\n",
    "# 1. Run k-means against our two features with three clusters.\n",
    "\n",
    "model = KMeans(n_clusters=k, random_state=42)\n",
    "model.fit(df[features].values)\n",
    "\n",
    "# 2. Assign clusters back to our DataFrame.\n",
    "#df['cluster'] = model.labels_\n",
    "\n",
    "# 3. Get our centroids.\n",
    "centroids = model.cluster_centers_\n",
    "cc = pd.DataFrame(centroids)\n",
    "\n",
    "# 4. Plot the scatter of our points with calculated centroids.\n",
    "def plot_kmeans(df, kmeans):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.scatter(df[features[0]], df[features[1]], c=df['cluster'])\n",
    "ax.scatter(cc[0], cc[1], marker='x', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that will plot the results of the three\n",
    "# clustering algorithms for comparison.\n",
    "\n",
    "def compare_clustering(df, n_clusters=3, dist=10, eps=1, min_samples=1):\n",
    "    # Plot df with Actual Labels\n",
    "    plot_clusters(df, 'Actual Labels')\n",
    "    \n",
    "    # Plot and score KMeans Clustering\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters).fit(df)\n",
    "    print('KMeans Inertia: ', kmeans_model.inertia_)\n",
    "    print('KMeans Silhouette: ', silhouette_score(df[['x','y']], kmeans_model.labels_))\n",
    "    \n",
    "    kmeans_centroids = kmeans_model.cluster_centers_\n",
    "    kmeans_cc = pd.DataFrame(kmeans_centroids)\n",
    "\n",
    "    base_colors = ['0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.45', '0.5', \n",
    "                   '0.55', '0.60', '0.65', '0.70', '0.75', '0.8', '0.85', '0.9', '0.95']\n",
    "    colors = [base_colors[centroid] for centroid in kmeans_model.labels_]\n",
    "\n",
    "    fig, ax =  plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.scatter(df['x'], df['y'], c=colors)\n",
    "    plt.title('KMeans Clustering with '+str(n_clusters) + ' clusters')\n",
    "    \n",
    "    # Plot and score Hierarchical Clustering\n",
    "    Z = linkage(df, 'ward')\n",
    "    clusters = fcluster(Z, dist, criterion='distance')\n",
    "    \n",
    "    colors_2 = [base_colors[i] for i in clusters]\n",
    "    \n",
    "    fig, ax =  plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.scatter(df['x'], df['y'], c=colors_2)\n",
    "    plt.title('Heirarchical Clustering with '+str(dist) + ' Dist')\n",
    "    \n",
    "    # Plot and score DBSCAN Clustering\n",
    "    ss = StandardScaler()\n",
    "    Xs = ss.fit_transform(df)\n",
    "    \n",
    "    dbscn = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    dbscn.fit(Xs)\n",
    "    \n",
    "    colors_3 = [base_colors[i] for i in dbscn.labels_]\n",
    "    \n",
    "    fig, ax =  plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.scatter(df['x'], df['y'], c=colors_3)\n",
    "    plt.title('DBSCN Clustering with '+str(eps) + ' Eps, and ' + str(min_samples) + ' Min. samples')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tinkering with clustering parameters.\n",
    "\n",
    "In the following sections, look at how the parameters affect the clustering algorithms and try to get clusters that make sense. There is no right answer here, as these are unsupervised techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.A) Find good parameters for the `flame` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.B) Find good parameters for the `agg` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.C) Find good parameters for the `comp` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.D) Find good parameters for the `jain` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.E) Find good parameters for the `pathbased` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.F) Find good parameters for the `r15` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.G) Find good parameters for the `spiral` data set.\n",
    "\n",
    "Which algorithm (visually) performs best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5) [Bonus] Explore other clustering algorithms.\n",
    "\n",
    "Scikit-learn comes with a variety of unsupervised clustering algorithms, some of which we haven’t covered in class. Two algorithms that may be particularly interesting to you are:\n",
    "\n",
    "1) [Affinity propagation](http://scikit-learn.org/dev/modules/clustering.html#affinity-propagation) finds clusters by sending messages from a group of points to other points. Points group into clusters based on a \"damping factor.\" Affinity propagation’s main appeal is that the number of clusters doesn’t need to be specified by the user (like DBSCAN).\n",
    "2) [Birch](http://scikit-learn.org/dev/modules/clustering.html#birch) finds clusters with a tree-based algorithm that is somewhat reminiscent of decision trees. It evaluates branches/nodes on a tree that best describe the data's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
